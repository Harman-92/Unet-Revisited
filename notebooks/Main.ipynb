{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# https://www.tensorflow.org/guide/data_performance#prefetching\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "base_dir = os.path.abspath('..')\n",
    "train_dir = os.path.join(base_dir,\"data\",\"train\")\n",
    "val_dir = os.path.join(base_dir,\"data\",\"test\")\n",
    "\n",
    "# # Image size that we are going to use\n",
    "# IMG_SIZE = 128\n",
    "# # Our images are RGB (3 channels)\n",
    "# N_CHANNELS = 3\n",
    "# # Number of classes + 1 for background\n",
    "# N_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_image(img_path: str) -> dict:\n",
    "    \n",
    "    \"\"\"Load an image and its annotation (mask) and returning\n",
    "    a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path : str\n",
    "        Image (not the mask) location.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping an image and its ground truth\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "\n",
    "    mask_path = tf.strings.regex_replace(img_path, \"original_retinal_images\", \"masks_new\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"jpg\", \"tif\")\n",
    "    \n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    \n",
    "    # The masks contain a class index for each pixels\n",
    "    mask = tfio.experimental.image.decode_tiff(mask)\n",
    "   \n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files(os.path.join(train_dir , 'original_retinal_images' , \"*.jpg\"), seed=seed)\n",
    "train_dataset = train_dataset.map(parse_image)\n",
    "\n",
    "val_dataset = tf.data.Dataset.list_files(os.path.join(val_dir , 'original_retinal_images' , \"*.jpg\"), seed=seed)\n",
    "val_dataset = val_dataset.map(parse_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([img['image'] for img in val_dataset.as_numpy_iterator()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.array([img['segmentation_mask'] for img in val_dataset.as_numpy_iterator()],dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 2848, 4288, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 2848, 4288, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "epochs = 50\n",
    "\n",
    "# Training path\n",
    "X_path= os.path.join(train_dir, 'original_retinal_images') # input image\n",
    "Y_path = os.path.join(train_dir, 'masks_new') # ground-truth label\n",
    "\n",
    "# Validation path\n",
    "val_X_path = os.path.join(val_dir, 'original_retinal_images')\n",
    "val_Y_path = os.path.join(val_dir, 'masks_new')\n",
    "\n",
    "# Train data generator\n",
    "x_gen_args = dict(\n",
    "                        rescale=1./255,\n",
    "                        #featurewise_center=True,\n",
    "                        #featurewise_std_normalization=True,\n",
    "                        #shear_range=0.2,\n",
    "                        #zoom_range=0.5,\n",
    "                        #channel_shift_range=?,\n",
    "                        #width_shift_range=0.5,\n",
    "                        #height_shift_range=0.5,\n",
    "                        rotation_range = 10,\n",
    "                        horizontal_flip=True\n",
    "                    )\n",
    "y_gen_args = dict(\n",
    "                        #featurewise_center=True,\n",
    "                        #featurewise_std_normalization=True,\n",
    "                        #shear_range=0.2,\n",
    "                        #zoom_range=0.5,\n",
    "                        #channel_shift_range=?,\n",
    "                        #width_shift_range=0.5,\n",
    "                        #height_shift_range=0.5,\n",
    "                        rotation_range = 10,\n",
    "                        horizontal_flip=True\n",
    "                    )\n",
    "\n",
    "image_datagen = ImageDataGenerator(**x_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**y_gen_args)\n",
    "\n",
    "image_datagen.fit(images, augment=True, seed=seed)\n",
    "mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    X_path,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True, # shuffle the training data\n",
    "    class_mode=None, # set to None, in this case\n",
    "    interpolation='nearest',\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    Y_path,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True,\n",
    "    class_mode=None,\n",
    "    interpolation='nearest',\n",
    "    seed=seed)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine image_ and mask_generator into one\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "num_train = len(image_generator)\n",
    "\n",
    "# val data generator\n",
    "image_datagen = ImageDataGenerator()\n",
    "mask_datagen = ImageDataGenerator()\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    val_X_path,\n",
    "    target_size=(h, w),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False, # we dont need to shuffle validation set\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    val_Y_path,\n",
    "    target_size=(h, w),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    seed=seed)\n",
    "\n",
    "val_generator = zip(image_generator, mask_generator)\n",
    "num_val = len(image_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the generators\n",
    "model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = num_train/batch_size, \n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps =num_val/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}